{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2885ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow import keras  \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout, MaxPooling2D, Activation, Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b8bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for all three datasets.\n",
    "#data_dir = Path(\"/Users/evachow/Documents/Documents - Evaâ€™s Mac mini/USD/ADS599/Capstone/chest_xray\")\n",
    "#train_dir = data_dir/\"train\"\n",
    "#val_dir = data_dir/\"val\"\n",
    "#test_dir = data_dir/\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72df2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for all three datasets.\n",
    "data_dir = Path(\"D:/USD-ADS_graduate/ADS-599/chest_xray/\")\n",
    "train_dir = data_dir/\"train\"\n",
    "val_dir = data_dir/\"val\"\n",
    "test_dir = data_dir/\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceda4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load the data into dataframes.\n",
    "# Assign labels corresponding to the folder names.\n",
    "\n",
    "def load_data(data_path):\n",
    "    # Below defines the directories for our \"NORMAL\" and \"PNEUMONIA\" images.\n",
    "    normal_dir = data_path/\"NORMAL\"\n",
    "    pneum_dir = data_path/\"PNEUMONIA\"\n",
    "    \n",
    "    # The images are in .jpeg format, so we will use glob() to retrieve\n",
    "    # file/pathnames that match the jpeg format.    normal_img = normal_dir.glob('*.jpeg')\n",
    "    normal_img = normal_dir.glob('*.jpeg')\n",
    "    pneum_img = pneum_dir.glob('*.jpeg')\n",
    "    \n",
    "    # Generate lists of our image data and image label.\n",
    "    img_data = []\n",
    "    img_label = []\n",
    "    \n",
    "    for img in normal_img:\n",
    "        img_data.append(img)\n",
    "        img_label.append('NORMAL')\n",
    "        \n",
    "    for img in pneum_img:\n",
    "        img_data.append(img)\n",
    "        img_label.append('PNEUMONIA')\n",
    "    df = pd.DataFrame(img_data,columns=['images'])\n",
    "    df['label'] = img_label\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8fff066",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define the training dataframe and sample randomly to check labeling.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_train \u001b[38;5;241m=\u001b[39m load_data(train_dir)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/generic.py:5773\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   5770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5771\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 5773\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5774\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   5776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/sample.py:150\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    151\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    152\u001b[0m )\n",
      "File \u001b[0;32mmtrand.pyx:909\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Define the training dataframe and sample randomly to check labeling.\n",
    "df_train = load_data(train_dir)\n",
    "print(df_train.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now define the validation and test dataframes.\n",
    "# Check the shape of our dataframes to ensure no image loss and correct shape.\n",
    "df_val = load_data(val_dir)\n",
    "df_test = load_data(test_dir)\n",
    "print('The training data has a shape of:',df_train.shape)\n",
    "print('The validate data has a shape of:',df_val.shape)\n",
    "print('The test data has a shape of:',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b15755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This new resizing function (defined as resizing2) will \n",
    "# resize an image to 224 x 224 pixels.\n",
    "def resizing2(img):\n",
    "    res_img = cv2.resize(img, (224,224))\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will change the color space of an image using the cv2 package.\n",
    "def gray_scale(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an image processing pipeline that resizes an image using resizing2\n",
    "# and applies the gray-scale function defined previously.\n",
    "def prepare(path, pipeline) : \n",
    "    img = cv2.imread(str(path))\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        img = transform(img)\n",
    "        \n",
    "    return img\n",
    "\n",
    "pipeline = [resizing2, gray_scale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the image processing pipeline to the training dataset.\n",
    "df_train['images'] = df_train['images'].apply(prepare,pipeline = pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad79848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the pixel values by dividing the values of the array by 255\n",
    "# and redefine our labels as binary values.\n",
    "for i in range(len(df_train)):\n",
    "    df_train['images'][i] = df_train['images'][i].astype(np.float32)/255\n",
    "    \n",
    "df_train['label'] = df_train['label'].astype(str)\n",
    "df_train['label'] = df_train['label'].map( {'NORMAL':0 , 'PNEUMONIA':1} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our predictor variable (images) and our target (label).\n",
    "x_train = np.array([df_train['images'][i] for i in range(len(df_train))])\n",
    "y_train = np.array(df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images from an array of 50176 to a dataframe.\n",
    "x_train_2dim = x_train.reshape((x_train.shape[0], 50176))\n",
    "le = LabelEncoder()\n",
    "y_train_2dim = le.fit_transform(df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62845c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_4dim = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "y_train_4dim = tf.keras.utils.to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the image processing pipeline to the validation dataset.\n",
    "df_val['images'] = df_val['images'].apply(prepare,pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab72a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the pixel values by dividing the values of the array by 255\n",
    "# and redefine our labels as binary values.\n",
    "for i in range(len(df_val)):\n",
    "    df_val['images'][i] = df_val['images'][i].astype(np.float32)/255\n",
    "    \n",
    "df_val['label'] = df_val['label'].astype(str)\n",
    "df_val['label'] = df_val['label'].map( {'NORMAL':0 , 'PNEUMONIA':1} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878eb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our predictor variable (images) and our target (label).\n",
    "x_val = np.array([df_val['images'][i] for i in range(len(df_val))])\n",
    "y_val = np.array(df_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images from an array of 50176 to a dataframe.\n",
    "x_val_2dim = x_val.reshape((x_val.shape[0], 50176))\n",
    "y_val_2dim = le.fit_transform(df_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b73dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_4dim = x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], 1)\n",
    "y_val_4dim = tf.keras.utils.to_categorical(y_val, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addd188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the image processing pipeline to the test dataset.\n",
    "df_test['images'] = df_test['images'].apply(prepare,pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b88105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the pixel values by dividing the values of the array by 255\n",
    "# and redefine our labels as binary values.\n",
    "for i in range(len(df_test)):\n",
    "    df_test['images'][i] = df_test['images'][i].astype(np.float32)/255\n",
    "    \n",
    "df_test['label'] = df_test['label'].astype(str)\n",
    "df_test['label'] = df_test['label'].map( {'NORMAL':0 , 'PNEUMONIA':1} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39bd6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our predictor variable (images) and our target (label).\n",
    "x_test = np.array([df_test['images'][i] for i in range(len(df_test))])\n",
    "y_test = np.array(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images from an array of 50176 to a dataframe.\n",
    "x_test_2dim = x_test.reshape((x_test.shape[0], 50176))\n",
    "y_test_2dim = le.fit_transform(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741596e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_4dim = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "y_test_4dim = tf.keras.utils.to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model.save('path/model.h5') to save a keras model.\n",
    "# model.save('saved_model/CNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ee8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back our saved model.\n",
    "CNN_model = tf.keras.models.load_model('saved_model/CNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b45427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loss and accuracy on our test data.\n",
    "cnn_loss, cnn_acc = CNN_model.evaluate(x_test_4dim, y_test_4dim, verbose=2)\n",
    "print('CNN model, accuracy: {:5.2f}%'.format(100 * cnn_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following restores the session while loading.\n",
    "# First, load the saved model.\n",
    "CNN_model = tf.keras.models.load_model('saved_model/CNN_model.h5')\n",
    "\n",
    "# Redefine functions to call the session.\n",
    "saver = tf.train.Saver()\n",
    "sess = keras.backend.get_sessions()\n",
    "saver.restore(sess, 'saved_model/CNN_session.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052856a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loss and accuracy on our test data.\n",
    "cnn_loss, cnn_acc = CNN_model.evaluate(x_test_4dim, y_test_4dim, verbose=2)\n",
    "print('CNN model, accuracy: {:5.2f}%'.format(100 * cnn_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
